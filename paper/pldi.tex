\documentclass[preprint,nocopyrightspace]{sigplanconf}
%\usepackage[square, comma, sort&compress]{natbib}

\usepackage{amsmath}
\usepackage{color}

\newcommand{\todo}[1]{\textcolor{red}{#1}}

\begin{document}

%\conferenceinfo{PLDI ’09}{ todo }

%\copyrightyear{2005}

%\copyrightdata{1-59593-056-6/05/0006}

\preprintfooter{DRAFT}

%\titlebanner{DRAFT}

\title{Effective Interactive Proofs for Imperative Programs}


\authorinfo{Double blind}
{ }

\maketitle

\begin{abstract}
  We present a redesign and reimplementation of the Ynot system for programming and verification of imperative programs in the Coq proof assistant.  We begin the ``practice'' part of the ``theory''-``practice'' pipeline, showing how the theory of Ynot can be used to craft a practical development environment, where it is possible to do full functional verification of imperative data structures with reasonable programmer effort.  For most implementations, the verification burden is reduced by at least an order of magnitude compared to the old Ynot system, replacing manual proof with automation.  The core of the automation is a simplification procedure for implications in higher-order separation logic, with hooks that allow programmers to add domain-specific simplification rules.
  
  Compared to competing approaches to data structure verification, our system includes much less code that must be trusted; namely, about a hundred lines of Coq code defining a program logic.  All of our theorems and decision procedures have or build machine-checkable correctness proofs from first principles, removing opportunities for tool bugs to create faulty verifications.  We argue for the effectiveness of our infrastructure by verifying a number of data structures and comparing to similar efforts within other projects.
\end{abstract}

%\category{CR-number}{subcategory}{third-level}

%\terms
%term1, term2

%\keywords
%keyword1, keyword2

\section{Introduction (GREG)}
\begin{itemize}
\item Want to verify imperative programs
\item Higher-order functions
\item modularity
\item {\it mom and apple pie}
\end{itemize}

  Ynot is the right design from a modularity, re-use perspective.  Much of the success hinges on the use of a higher-order dependently-typed language (Coq) and the ability to smoothly integrate modeling (inductive definitions), domain-specific abstractions (e.g., STsep) and uniform abstraction (Pi). If Ynot is to succeed, need drastic improvements in automation.


\section{Overview (GREG)}
\begin{itemize}
\item Features of Ynot
\item problem with the proofs
\end{itemize}


\section{Method (ADAM)}
\subsection{Unary Post-conditions}
More standard separation logic

enables automatic reasoning

\subsection{Proof Automation}
higher order tactic for understanding separation logic

domain extensions {\tt llseg}, {\tt array}, (hprop)

Three parts: Model, Lemmas, hints and tactics

\subsection{Comparison to Previous Ynot (AVI)}

 The original formulation of Ynot lead to large, unwieldy proofs.
 Reasoning about separation logic connectives was done at the heap
 level; a larger fraction of all of our proof scripts simply massaged
 subeaps into appropriate forms.  We had some tactics that implemented
 basic operations, such as the split, join, and flattening of
 sub-heaps, but the proof writer was forced to stitch them together to
 force the heaps into the correct form.

 The focus of our re-implementation of the Ynot system has been proof
 automation.  Throught the use of the sep tactic, we have virtually
 eliminated the need to reason about heaps; reasoning is done at the
 level of seperation logic.  Much of this reasoning has in turn been
 automated by a set of tactics such as \texttt{sep auto}. These
 tactics reduce the need to reason about the connectives of separation
 logic and their properties, allowing the proof writer to focus on the
 domain specific parts of the proof.  For proofs that only have simple
 domain specific parts, \texttt{sep auto} is often able to prove them
 on its own.

 The new model uses ``ghost variables'' to simplify specifying
 properties. It does so in a way that guarantees that they are
 computationally irrelevant, and so can always be eliminated when a
 program is extracted.  This in turn allows the new model to use unary
 post-conditions, which greatly simplifies specifications and enables
 the greater automation.  The old model used binary post-conditions to
 obviate the need for ghost variables.  Binary post-conditions where
 generally harder to reason about, since the connection between pre-
 and post-conditions always needed to be re-established.  In the new
 style, the connection is built in to the specification.

 In the new Ynot, proofs are an order of magnitude shorter then they
 where in the old Ynot. (provide numbers here)
\section{Evaluation}
\begin{figure*}
\begin{center}
\begin{tabular}{r | r | r | r | r | r | r | r}
 & lines of code & total  non-code & annotations & lemmas & proofs & aux. def & tactics\\\hline
{\tt LL-ref} & AVI\\
{\tt LL-Jahob} & RYAN\\
{\tt LL-Smallfoot} & GREGORY\\
{\tt Hashtable} & AVI\\
{\tt Binary Heap} & RYAN\\
{\tt BST} & ??\\
{\tt Stack} & ADAM\\
{\tt Queue} & ADAM\\
\end{tabular}
\end{center}
\end{figure*}

\section{Related Work}
\subsection{Jahob (RYAN)}

The Jahob system~\cite{jahob} allows the specification and verification 
of recursive, linked data structures in a fragment of Java.  Like ynot, 
verified programs are correct up to termination.  

Jahob specifications are written in classical higher order logic.  
The abstract state of an object is given by s a collection of 
programmer defined ``specvars'' which do not exist during program execution.
Specvars are defined by Jahob formulae, which resemble formulae of set 
theory in Isabelle/HOL.  Jahob formulae are simply typed with ground types
bool, obj, and int, type constructors $\Rightarrow$ for total functions, * for tuples
and set for sets.  The logic contains polymorphic equality, standard
logical connectives $\wedge, \vee, \neg, \to, \forall, \exists$ and
$\lambda$ binders, set comprehension, operations on sets ($\cup, \in$) 
and transitive closure, finite set cardinality, and a tree function for indicating
that a structure is a tree.  Here is the interface for a Jahob association list: 

\begin{verbatim}
class AssocList {
//: public specvar content :: "(obj * obj) set
public Object put(Object k0, Obkect v0)
/*: requires "k0 <> null /\ v0 <> null"
    modifies content
    ensures  
    "content = old content 
               - {(k0, result)} U {(k0, v0)} 
     /\ (result =  null -> 
          ~ exists v, 
             (k0, v) in old content) /\
     /\ (result <> null -> 
           (k0, result) in old content) */
{...}
public Object get(Object k0)
/*: requires "k0 <> null"
    ensures  
    "result =  null -> 
      ~ exists v, (k0, v) in content 
      /\ result <> null -> 
           (k0, result) in content" */
}
\end{verbatim}

Like ynot, Jahob relates the abstract state of a data structure to its concrete heap representation.  
One way to implement the association list with a singly linked list is to represent links between 
nodes using an edge relation (vardef is a shorthand definition):

\begin{verbatim}
public /*: claimedBy AssocList */ 
class Node {
    public Object key; public Object value; 
    public Node next;
    //: public ghost specvar cnt 
         :: "(obj * obj) set" = "{}"
}
private static specvar edge 
  :: ``obj => obj => bool'';

vardefs ``edge == (fun x y => 
  (x in Node /\ y = x..next) \/
  (x in AssocList /\ y = x..first))'';
invariant InjInv: forall x1 x2 y,
   y <> null /\ edge x1 y 
   /\ edge x2 y -> x1 = x2'';
\end{verbatim} 

The (recursive) representation invariant defines the members of the abstract set 
representing the linked list as the union of the element in the head node 
and the members of the subsequent nodes.  It also ensures that keys only occur once in the list.

\begin{verbatim}
private Node first;

vardefs "content == first..cnt";

invariant CntDef:
    ``forall x, x in Node /\ x in alloc 
        /\ x <> null ->
           x..cnt = {(x..key, x..value)} 
              U x..next..cnt /\
           (forall v, (x..key, v) 
              notin x..next..cnd)'';
invariant CntNull:
    ``forall x, x in Node /\ x in Alloc 
        /\ x = null -> x..cnt = {}'';
\end{verbatim}

Ynot's approach to specification and abstract state is similar in spirit to Jahob's but 
feels more computational in practice.
Because ynot is embedded in Coq, specifications and programs share a common language.
This makes it possible to define specifications using programs with reduction behavior
rather than with formulae of set theory; reasoning about such computational entities
is at the core of ynot's proof automation.  In addition, ynot uses separation connectives
to describe the heap.  For instance, the representation invariant rep for the ynot
singly linked list implementation is defined as a Coq fixpoint of essentially a separation logic formula:

\begin{verbatim}
Variables K V: Set.
Variable eqK : forall (k1 k2: K), {k1=k2} + {k1<>k2}.

Record Node : Set := node {
  key: K; value: V; next: option ptr
}.

Definition AssocList : Set := ptr.

Fixpoint rep' (m : list (prod K V)) 
(p : option ptr) {struct m} : hprop :=
  match p with
    | None => [m = nil]
    | Some hd => 
      match m with
        | (k,v) :: b => Exists nxt :@ option ptr, 
             hd --> node k v nxt * rep' b nxt
        | nil => [False]
      end
  end.

Definition rep (m: list (prod K V)) 
 (ll: AssocList) : hprop :=
   Exists n :@ option ptr, 
    ll --> n * rep' m n.
\end{verbatim}

The computational behavior of specification means, for instance, that the type of new
\begin{verbatim}
Definition new : STsep __ (rep nil).
\end{verbatim}

is definitionally equal to 
\begin{verbatim}
  STsep __ (fun p => match p with 
                       | None => [nil = nil] 
                       | Some hd => [False]
                     end)
\end{verbatim}

and so it is easy to automate (using a tactic called t) the reasoning that proves
the new association list allocator is correct:
\begin{verbatim}
Definition new : STsep __ (rep nil).
  refine {{ New None }}; t. Qed.
\end{verbatim}

The specifications for put and lookup exploit other pure functional programs:

\begin{verbatim}
Fixpoint lookup (k: K) 
  (l: list (prod K V)) : option V :=
 match l with
  | nil => None
  | (k', v)::b => if eqK k k' 
                  then Some v 
                  else lookup k b
 end.

todo - change put 
Definition put (ll : AssocList) 
 (m : [list (prod K V)]) (k : K) (v : V) :
  STsep (m ~~ rep m ll)
        (fun _:unit => m ~~ rep ((k,v)::m) ll ).

Definition get'' (k: K) (hd: option ptr) 
 (m: [list (prod K V)]) : 
  STsep (m ~~ rep' m hd)
        (fun res:option V => m ~~ 
           [res = lookup k m] * rep' m hd).
\end{verbatim} 

The actual implementations of get in ynot and jahob are essentially identical.
In both cases annotations are required to guide the proving process.  (Add numbers here).
In Jahob:

\begin{verbatim}
/*: requires ``k0 <> null''
    ensures 
      ``(result <> null -> 
          (k0, result) in content 
          /\ (result =  null -> 
                ~exists v0, 
                  (k0, v) in content)) */
{
  Node current = first;
  while //: inv ``forall v, ((k0, v) in content) 
                    = ((k0, v) in current..cnt)''
   (current != null) {
     if (current.key == k0) { 
       return current.value; 
     }
     current = current.next
  }
  return null;
}
\end{verbatim}

In ynot:

\begin{verbatim}
Definition get (k: K) 
 (hd: option ptr) (m: [list (prod K V)]):
  STsep (m ~~ rep' m hd)
        (fun res:option V => m ~~ 
           [res = lookup k m] * rep' m hd).
intro k.
refine (Fix2
    (fun hd m => m ~~ rep' m hd)
    (fun hd m o => m ~~ 
       [o = lookup k m] * rep' m hd)
    (fun self hd m =>
      IfNull hd
      Then {{ Return None }}
      Else fn <- hd !! fun fn => m ~~ 
             [head m = Some (key fn, value fn)] 
             * rep' (tail m) (next fn);
           if eqK (key fn) k
           then {{ Return (Some (value fn)) }}
           else {{ 
            self (next fn) (m ~~~ tail m) 
              <@> (m ~~ hd --> fn * 
                  [head m = Some (key fn, value fn)]) 
           }}
      )); try solve [ t | hdestruct m; t ].
Defined.

Definition get (k: K) 
 (ll: AssocList) (m: [list (prod K V)]) :
   STsep (m ~~ rep m ll)
         (fun r:option V => m ~~ 
            rep m ll * [r = lookup k m]).
intros; refine (hd <- !ll;
    Assert (ll --> hd * (m ~~ rep' m hd));;
    {{get'' k hd m <@> _}});
  t.
\end{verbatim}

Whereas ynot's automated reasoning is completely captured by Coq tactics,
Jahob programs are verified using a series of stages similar to 
a compiler pipeline.  First, Jahob programs are translated into 
an extended guarded command language.
Then, Jahob generates verification conditions which are discharged 
using a combination of theorem provers -- if one prover does not succeed 
on an obligation, another is tried.  This allows Jahob to run multiple
provers in parallel.  Because provers are often specialized to particular
classes of formulae, formula approximation techiques must be used to integrate them with
a system using higher order logic. Jahob supports a number of 1st order and SMT provers, and also the 
MONA prover for the monadic fragment of 2nd order logic and Isabelle and Coq. 

 \subsection{Smallfoot (GREGORY)}
We conclude our comparison with alternative approaches by comparing
our system to Smallfoot~\cite{small1,small2}. The focus of Smallfoot
is on compltely automatic reasoning, and it's almost complete nature
makes many correct programs go through with only the function level
annotations, a goal, but not yet a complete reality in Ynot. In
addition to the focus on automatic proofs, Smallfoot includes simple
concurrency primitives, $||$ and $\mathsf{with}\,r\,\mathsf{when}(B)
C$ with which they are able to implement a producer-consumer
model. Based on these points, we will draw a comparison in two parts:
the size of annotations and proof obligations and the expressivity of
the logic.

On the size of proof obligations, the Smallfoot system comes out
ahead, requiring no user-constructed proofs. The drawback to this is
that only inductive data of the following types are allowed: singly
linked lists, doubly linked lists, trees and xor lists. This
restriction is necessary to Smallfoot in order to make the proofs
decidable.

The annotations in the example programs are small mainly because they
use these. While the predicates are hard-coded in Smallfoot,
predicates can be coded directly by the user in Ynot. The style of
Ynot representations are to express data by mapping a ``ghost''
representation into a heap representation. This approach allows
stronger dependent types in the contracts for functions, requireing
the accompanying proof to be a proof of partial correctness rather
than simply of resource constraints. For example, consider the
function to test whether a list is empty in Smallfoot and in Ynot.
\begin{verbatim}
is_empty(r;l) [l |-> t * list(t)] {
  local p;
  p = l->p;
  if (p == NULL) { r = 1; } 
  else { r = 0; }
} [l|-> t * list(t)]
\end{verbatim}

The following function also has the same type:
\begin{verbatim}
is_empty(r;l) [l |-> t * list(t)] {
  r = 1;
} [l|-> t * list(t)]
\end{verbatim}
In Ynot, the \verb|is_empty| function can be defined as follows:
\begin{verbatim}
Definition is_empty A (ll : LinkedList)
  (m : [list A]) :
  STsep (m ~~ rep m ll) 
    (fun res:bool => m ~~ match res with
                            | nil => [res = true]
                            | _   => [res = false]
                          end).
  intros;
  refine (hd <- !ll;
          IfNull hd Then {{Return true}}
          Else {{Return false}}); sep simpl.
Qed.          
\end{verbatim}
The type guarantees that the function is implemented correctly with
respect to the underlying list.

\todo{This is analagous to the implementation of llseg presented in
  the smallfoot paper.}
For example, the following fixpoint expresses the recursive definition
of a linked list segement.  \todo{What is the best way to encode a
  linked list segment?}
\begin{verbatim}
Fixpoint llseg A (hd tl : option ptr) 
  (m : list A) {struct m} :=
  match m with 
    | nil => [hd = tl]
    | a :: b => 
      match hd with 
        | None => [False]
        | Some p => [hd <> tl] * 
            Exists nxt :@ option ptr, 
              hd --> node a nxt * llseg nxt tl b
      end
  end.
\end{verbatim}




Comparison points
\begin{itemize}
\item The use of Coq allows quantifiers in formula. (makes inference
  more difficult but allows more expressive types)
\item Ynot is capble of arbitrary inductive predicates
\item Ynot does not support concurrency which is a strength of
  smallfoot (race detection)
\item Smallfoot is very fast
\item A lot of the ``parallel examples'' don't actually use
  synchronization. These would be pretty trivial to implement in Ynot
  with a function:
\begin{verbatim}
SepParallel (r1 r2 : Type) (P_i Q_i : hprop)
  (P_e : r1 -> hprop) (Q_e : r2 -> hprop) :
     STsep (P_i) (P_e) -> STsep (Q_i) (Q_e)
  -> STsep (P_i * Q_i) (fun r:(r1 * r2) => 
               (P_e (fst r)) * (Q_e (snd r)))
\end{verbatim}
the more interesting aspect of the parallelism comes from the locking
mechanism, which could be encoded in Ynot but only after a little bit
of hacking. (smallfoot uses resource invariants to control this)
\end{itemize}

Smallfoot examples:
\begin{itemize}
\item circular list
\item doubly linked list
\item merge sort
\item ``memory manager'' (basically just a stack)
\item queue
\item tree
\item xor linked list segment
\item xdeq --- uses parallelism (reading and writing buffer)
\end{itemize}

\section{Other related work}


\section{Conclusions \& Future Work}
Irrelevance, concurrency, IO/effects

automation/annotations (loop invariant inference)

Check that bibliography is working~\cite{htt}.

%\bibliographystyle{plainnat}
\bibliographystyle{plain}

\bibliography{bib}

\end{document}
